import argparse
import os

import json
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset
import torch.nn.functional as F

from model import PartMatchingTransformer

def str2bool(v):
    if v.lower() in ('yes', 'true', 't', 'y', '1'):
        return True
    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
        return False
    else:
        raise argparse.ArgumentTypeError('Boolean value expected.')

class PreloadedEpisodeDataset(Dataset):

    """
    For each episode, we generate a new dataset preloaded according to the episode txt file. 
    """

    def __init__(self, feature_dict, class_id2query_paths, class_id2support_paths):
        
        self.feature_dict = feature_dict
        # For each path, we have a dictionary with keys:
        # 'part_features': np.ndarray of shape (num_parts, feature_dim), note that the final part feature (part_features[-1]) is the global image feature generated by the part encoder.
        # 'part_indices': np.ndarray of shape (num_parts,) referring to the pixel value of parts in the original segmentation map. The final part index (part_indices[-1]) is set to 1000, which is a special value indicating the global image feature.


        self.id2query_paths = class_id2query_paths
        # id2query_paths: {class_id1: [query_path1, query_path2, ...], class_id2: [query_path1, query_path2, ...], ...}
        self.id2support_paths = class_id2support_paths
        # id2support_paths: {class_id1: [support_path1, support_path2, ...], class_id2: [support_path1, support_path2, ...], ...}

        self.query_path2id = {}  
        self.query_paths = []
        for class_id in self.id2query_paths:
            for path in self.id2query_paths[class_id]:
                self.query_paths.append(path)
                self.query_path2id[path] = class_id
   
        self.generate_dataset()

    def generate_dataset(self):

        all_paths = []
        all_features = []
        all_part_indices = []
        all_source_ids = [] 
        all_targets = []

        for query_path in self.query_paths:
            query_class_id = self.query_path2id[query_path]
            paths = []
            features = []
            part_indices = []
            source_ids = []
            features.append(self.feature_dict[query_path]['part_features'])
            part_indices.append(self.feature_dict[query_path]['part_indices'])
            paths.extend([query_path] * len(self.feature_dict[query_path]['part_features']))
            source_ids.extend([0] * len(self.feature_dict[query_path]['part_features']))  # 0 for query
            target = None
            for i, class_id in enumerate(self.id2support_paths):
                if class_id == query_class_id:
                    target = i
                for support_path in self.id2support_paths[class_id]:
                    features.append(self.feature_dict[support_path]['part_features'])
                    part_indices.append(self.feature_dict[support_path]['part_indices'])
                    paths.extend([support_path] * len(self.feature_dict[support_path]['part_features']))
                    source_ids.extend([i + 1] * len(self.feature_dict[support_path]['part_features']))
            features = np.concatenate(features, axis=0)
            part_indices = np.concatenate(part_indices, axis=0)
            source_ids = np.array(source_ids)  # Changed from encodings
            all_paths.append(paths)
            all_features.append(features)
            all_part_indices.append(part_indices)
            all_source_ids.append(source_ids)  # Changed from all_encodings

            assert target is not None
            all_targets.append(target)

        self.paths = all_paths
        self.features = all_features
        self.part_indices = all_part_indices
        self.source_ids = all_source_ids
        self.targets = all_targets

    def __len__(self):
        return len(self.paths)
    
def __getitem__(self, idx):
    return self.paths[idx], torch.from_numpy(self.features[idx]), torch.tensor(self.part_indices[idx]).long(), torch.tensor(self.source_ids[idx]).long(), \
        torch.tensor(self.targets[idx]).long()

def collate_fn(batch):
    paths, features, part_indices, source_ids, targets = [list(items) for items in zip(*batch)]
    max_len = max([len(f) for f in features])
    is_padding = [torch.zeros(len(f), dtype=torch.bool) for f in features]
    for i in range(len(features)):
        features[i] = torch.cat([features[i], torch.zeros(max_len - len(features[i]), features[i].shape[1])], dim=0)
        part_indices[i] = torch.cat([part_indices[i], -1 * torch.ones(max_len - len(source_ids[i]), dtype=torch.long)], dim=0) 
        source_ids[i] = torch.cat([source_ids[i], torch.ones(max_len - len(source_ids[i]), dtype=torch.long)], dim=0)
        is_padding[i] = torch.cat([is_padding[i], torch.ones(max_len - len(is_padding[i]), dtype=torch.bool)], dim=0)
        paths[i] = paths[i] + [''] * (max_len - len(paths[i]))
    
    features = torch.stack(features)
    part_indices = torch.stack(part_indices)
    source_ids = torch.stack(source_ids) 
    is_padding = torch.stack(is_padding)
    dict_batch = {
        'paths': paths,
        'features': features,
        'part_indices': part_indices,
        'source_ids': source_ids, 
        'is_padding': is_padding,
        'targets': torch.stack(targets),
    }

    return dict_batch

def evaluate_episode(query, support, features_dict, model):
    dataset = PreloadedEpisodeDataset(features_dict, query, support)
    dataloader = torch.utils.data.DataLoader(dataset, len(dataset), shuffle=False, num_workers=0, collate_fn=collate_fn)
    batch = next(iter(dataloader))
    device = torch.device('cuda')
    features = batch['features'].to(device)
    source_ids = batch['source_ids'].to(device)  # Changed encodings to source_ids
    is_padding = batch['is_padding'].to(device)
    targets = batch['targets'].to(device)
    accuracy = []
    with torch.no_grad():
        logits = model(features, source_ids, is_padding)  # Changed encodings to source_ids
        preds = torch.argmax(logits, dim=1)
        batch_accuracies = (preds == targets).float().cpu().numpy().tolist()
        accuracy.extend(batch_accuracies)
    return accuracy

def main():

    parser = argparse.ArgumentParser(
            description="Testing", allow_abbrev=False
        )
    parser.add_argument("--data_dir", default='data/', type=str, help="location to features")
    parser.add_argument("--dataset", default='hotels', type=str, help="dataset")
    parser.add_argument("--part_encoder", default='dinov2', type=str, help="part encoding method")
    parser.add_argument("--checkpoint", default='checkpoints/hotels_dinov2/best.pt', type=str, help="location to images")
    parser.add_argument("--n_shots", default=1, type=int, help="number of shots")
    parser.add_argument("--n_ways", default=20, type=int, help="number of ways")
    parser.add_argument("--num_layers", default=4, type=int, help="number of transformer layers")
    parser.add_argument("--num_heads", default=8, type=int, help="number of attention heads")
    parser.add_argument("--input_feat_dim", default=768, type=int, help="dimension of precomputed part embeddings")
    parser.add_argument("--dim_model", default=768, type=int, help="dimension of model")
    parser.add_argument("--dim_ff", default=768 * 2, type=int, help="dimension of feedforward layer")
    parser.add_argument("--num_workers", default=12, type=int, help="num dataloading workers")
    parser.add_argument("--pos_encodings", default=True, type=str2bool, help="pos encodings")
    args = parser.parse_args()

    K = args.n_shots
    N = args.n_ways
    if 'hotel' in args.dataset.lower():
        episode_filepath = os.path.join(args.data_dir, args.dataset, 'test_episodes', f'{N}way_{K}shot.json')
        with open(episode_filepath) as f:
            episodes = json.load(f) # a list of episodes, each epsisode in the form of [{support_class_1: [support_path_1, support_path_2, ...], support_class_2: [support_path_1, support_path_2, ...]}, {query_class_1: [query_path_1, query_path_2, ...], query_class_2: [query_path_1, query_path_2, ...]}]
            f.close()

        features_dict = np.load(os.path.join(args.data_dir, args.dataset, 'features', f'{args.dataset}_{args.part_encoder}.npy'), allow_pickle=True).item()
    else:
        raise ValueError(f'Invalid dataset: {args.dataset}')

    model = PartMatchingTransformer(num_layers=args.num_layers, num_heads=args.num_heads, dim_model=args.dim_model, dim_ff=args.dim_ff, num_sources=N + 1, dim_token=args.input_feature_dim,
                                      dropout=0., pos_encodings=args.pos_encodings)

    sd = torch.load(args.checkpoint)
    sd = {k.replace('module.', ''): v for k, v in sd.items()}
    model.load_state_dict(sd, strict=True)
    model.cuda()
    model.eval()

    episode_accuracies = []
    for i, (support, query) in enumerate(episodes):
        episode_accuracy = evaluate_episode(query, support, features_dict, model)
        episode_accuracies.extend(episode_accuracy)

    print(f'Accuracy for {N}-way, {K}-shot: {np.mean(episode_accuracies)}, using checkpoint: {args.checkpoint}')
    
if __name__ == "__main__":
    main()