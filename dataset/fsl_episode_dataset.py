import os
import random
from collections import defaultdict

import torch
import torch.nn as nn
import numpy as np

class EpisodeDataset(torch.utils.data.Dataset):
    def __init__(self, data_dir, dataset='hotels', part_encoder='dinov2',  ways=[5, 20], shots=[5, 20], split='train', token_dropout=.0):
        
        self.feature_dict = np.load(os.path.join(data_dir, dataset, 'features', f'{dataset}_{part_encoder}.npy'), allow_pickle=True).item()
        # For each path, we have a dictionary with keys:
        # 'part_features': np.ndarray of shape (num_parts, feature_dim), note that the final part feature (part_features[-1]) is the global image feature generated by the part encoder.
        # 'part_indices': np.ndarray of shape (num_parts,) referring to the pixel value of parts in the original segmentation map. The final part index (part_indices[-1]) is set to 1000, which is a special value indicating the global image feature.

        self.ways = ways
        self.shots = shots
        self.token_dropout = token_dropout
        self.split = split
        self.paths2ids = {}
        self.id2paths = {}

        if 'hotels' in dataset:
            self.split_hotel_ids = set()
            with open(f'data/{dataset}/splits/{split}_classes.txt', 'r') as f:
                for line in f:
                    hotel_id = line.strip()
                    if hotel_id:  # Skip empty lines
                        self.split_hotel_ids.add(hotel_id)

            for path in list(self.feature_dict.keys()):
                hotel_id = path.split('/')[-2]
                if hotel_id not in self.split_hotel_ids:
                    del self.feature_dict[path]
                else:
                    if hotel_id not in self.id2paths:
                        self.id2paths[hotel_id] = []
                    self.paths2ids[path] = hotel_id
                    self.id2paths[hotel_id].append(path)
            
            self.paths = list(self.feature_dict.keys())

        else:
            raise ValueError("Dataset not supported")

    def __len__(self):
        return len(self.feature_dict)

    def gather_support_part_features(self, hotel_id, shots, perm=None, exclude_path=None):
        all_possible_paths = self.id2paths[hotel_id]
        paths = []
        features = []
        part_indices = []
        if perm is None:
            perm = np.random.permutation(len(all_possible_paths))
        for idx in perm:
            path = all_possible_paths[idx]
            if exclude_path is None or path not in exclude_path:
                features.append(self.feature_dict[path]['part_features'])
                part_indices.append(self.feature_dict[path]['part_indices'])
                for _ in range(len(self.feature_dict[path]['part_features'])):
                    paths.append(path)
            if len(features) >= shots:
                break

        if len(features) > 0:
            features = torch.from_numpy(np.concatenate(features, axis=0))
            part_indices = torch.from_numpy(np.concatenate(part_indices, axis=0))
        return paths, features, part_indices

    def gather_query_part_features(self, path):
        features = self.feature_dict[path]['part_features']
        part_indices = self.feature_dict[path]['part_indices']
        paths = [path] * len(features)
        return paths, torch.from_numpy(features), torch.from_numpy(part_indices)

    def get_episode(self, index):

        '''
        When sampling an episode for training/validation, we select 1 query image first, which is the 'lead' query.
        We sample shots number of images from the lead query class to use as support.
        Then we sample (ways - 1) negative classes, and for each class, we sample shots number of images.
        The lead query is always the first class, and it is assigned a target of 0.
        The negative classes are assigned targets from 1 to (ways - 1).
        Then, for each negative support class as the query, we sample an image from that class
          not selected as support to use as a query and fill out the batch
        Result is a batch of size ways
        '''

        lead_query_path = self.paths[index]
        lead_query_class = self.paths2ids[lead_query_path]
        negative_classes = []

        if type(self.ways) == int:
            ways = self.ways
        else:
            ways = np.random.randint(self.ways[0], self.ways[1] + 1)

        if type(self.shots) == int:
            shots = self.shots
        else:
            shots = np.random.randint(self.shots[0], self.shots[1] + 1)

        while len(negative_classes) < ways - 1:
            neg_class = np.random.choice(list(self.id2paths.keys()))
            if neg_class != lead_query_class and neg_class not in negative_classes:
                negative_classes.append(neg_class)

        lead_query_paths, lead_query_features, lead_query_partt_indices = self.gather_query_part_features(lead_query_path)
        lead_query_source_ids = torch.tensor([0] * len(lead_query_paths))
        
        all_query_paths = [lead_query_paths]
        all_query_features = [lead_query_features]
        all_query_part_indices = [lead_query_partt_indices]
        all_query_source_ids = [lead_query_source_ids]

        targets = [0]

        support_paths = []
        support_features = []
        support_part_indices = []
        support_source_ids = []
        support_classes = [lead_query_class] + negative_classes

        for i, cla in enumerate(support_classes):
            exclude_path = lead_query_path if i == 0 else None # to avoid selecting the lead query path as support
            paths, features, part_indices = self.gather_support_part_features(cla, shots=shots, exclude_path=exclude_path)
            if len(features) > 0:
                support_paths.extend(paths)
                support_features.append(features)
                support_part_indices.append(part_indices)
                support_source_ids.extend([i + 1] * len(features))

        support_paths_set = set(support_paths)

        # get remaining query paths

        for idx, cla in enumerate(support_classes):
            if idx == 0:
                continue
            possible_paths = [p for p in self.id2paths[cla] if p not in support_paths_set]

            if len(possible_paths) > 0:
                query_path = random.choice(possible_paths)
                query_paths, query_features, query_part_indices = self.gather_query_part_features(query_path)
                all_query_paths.append(query_paths)
                all_query_features.append(query_features)
                all_query_part_indices.append(query_part_indices)
                all_query_source_ids.append(torch.tensor([0] * len(query_features)))
                targets.append(idx)

        max_query_length = max([len(f) for f in all_query_features])
        is_padding_query = torch.zeros(len(all_query_features), max_query_length)

        support_features = torch.cat(support_features, dim=0).tile(len(all_query_features), 1, 1)
        support_source_ids = torch.tensor(support_source_ids).long().tile(len(all_query_features), 1)
        support_part_indices = torch.cat(support_part_indices, dim=0).tile(len(all_query_features), 1)
        is_padding_support = torch.zeros_like(support_features[:, :, 0])
        support_paths = [support_paths] * len(all_query_features)

        # add padding to query features
        for i, f in enumerate(all_query_features):
            if len(f) < max_query_length:
                all_query_features[i] = torch.cat([f, torch.zeros(max_query_length - len(f), f.shape[1])])
                all_query_part_indices[i] = torch.cat([all_query_part_indices[i], -1 * torch.ones(max_query_length - len(f))])
                all_query_source_ids[i] = torch.cat([all_query_source_ids[i], -1 * torch.ones(max_query_length - len(f)).long()])
                is_padding_query[i, len(f):] = 1
        
        query_features = torch.stack(all_query_features)
        query_part_indices = torch.stack(all_query_part_indices)
        query_source_ids = torch.stack(all_query_source_ids)
        targets = torch.tensor(targets).long()

        # Concatenate query and support features 
        features = torch.concat([query_features, support_features], dim=1)
        part_indices = torch.concat([query_part_indices, support_part_indices], dim=1)
        source_ids = torch.concat([query_source_ids, support_source_ids], dim=1)
        is_padding = torch.concat([is_padding_query, is_padding_support], dim=1).long()

        paths = [p + q for p, q in zip(all_query_paths, support_paths)]

        if self.token_dropout > 0:
            dropout_mask = torch.rand(source_ids.shape) < self.token_dropout
            features[dropout_mask] = 0.
            is_padding[dropout_mask] = 1
            part_indices[dropout_mask] = -1
            source_ids[dropout_mask] = -1

        return {
            'features': features,
            'part_indices': part_indices,
            'source_ids': source_ids,
            'is_padding': is_padding,
            'targets': targets,
            'paths': paths,
        }

    def __getitem__(self, index):
        return self.get_episode(index)

